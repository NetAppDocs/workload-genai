---
sidebar: sidebar
permalink: deploy-infrastructure.html
keywords: ai, chatbot, infrastructure, bedrock, fsx for ontap
summary: You need to deploy the chatbot infrastructure in your environment before you can build knowledgebases and chatbots for your organization. The primary infrastructure components are the Amazon Bedrock AI service, a virtual machine instance for the NetApp AI engine, and an FSx for ONTAP file system.
---

= Deploy the knowledgebase infrastructure
:icons: font
:imagesdir: ./media/

[.lead]
You need to deploy the chatbot infrastructure in your environment before you can build knowledgebases and chatbots for your organization. The primary infrastructure components are the Amazon Bedrock AI service, a virtual machine instance for the NetApp AI engine, and an FSx for ONTAP file system.

The deployed infrastructure can support multiple knowledgebases and chatbots, so you'll typically only need to perform this task once.

image:diagram-chatbot-infrastructure.png[A diagram of the AI chatbot components.]

The items in green boxes are deployed during this procedure. The other elements must be in place before starting the deployment.

== Infrastructure details

The infrastructure consists of the following components.

Amazon Bedrock service::
Amazon Bedrock is a fully managed service that enables you to use foundation models (FMs) from leading AI companies via a single API. It also provides the capabilities you need to build secure generative AI applications.
+
https://aws.amazon.com/bedrock/[Learn more about Amazon Bedrock].

Virtual machine for the NetApp AI engine::
The NetApp AI engine gets deployed during this process. It provides the processing power to ingest the data from your data sources and then write that data in the database.

FSx for ONTAP file system::
The FSx for ONTAP system provides the storage for your AI system. 
+
* One or more volumes contain the data sources that you'll integrate into your knowledgebase.
* One volume contains the database that stores the data that has been generated by the foundational model based on your data sources.

The NetApp AI engine monitors and interacts with both of these volumes.

== Deploy the infrastructure

You'll need to enter your AWS credentials and select the FSx for ONTAP file system to deploy the infrastructure.

.Before you begin

Make sure your environment meets link:knowledgebase-prerequisites.html[the requirements] before you start this procedure.

.Steps

. Log in to Workload Factory.

. In the AI workloads tile, click *Deploy & manage* and the Deploy chatbot infrastructure page is displayed.

. Review the infrastructure diagram and click *Next*. 

. Complete the items in the "AWS settings" section of the Define infrastructure page: 

.. *AWS credentials*. When running in Read or Automate mode, select or add the AWS credentials that provide permissions to deploy the AWS resources. 
+
When running in Basic mode you can continue without credentials, but you'll need to copy the code in the Codebox for CloudFormation and add credentials manually after you're logged into AWS.

.. *Location*. Select the AWS region, VPC, and Subnet. 
+
Your instance of Amazon Bedrock must be located in the same region and VPC.

. Complete the items in the "Infrastructure settings" section of the Define infrastructure page: 

.. *FSx for ONTAP system*. Select the FSx for ONTAP file system and the storage VM where the AI instance database volumes will be deployed, and then specify the name you want to use for the volume.
+
Depending on whether or not Workload Factory has the credentials for the FSx for ONTAP system, you may need to enter the user name and password.

.. *Tags*. Enter any tag key/value pairs that you want to have applied to all the AWS resources that are part of this deployment.

. *Key pair*. Select a key pair that allows you to securely connect to the NetApp AI engine instance.

. Click *Deploy* to begin the deployment.

.Result

The chatbot infrastructure is deployed and you can start to build your first knowledgebase.

During the deployment process, the following items are set up:

* The network is set up along with the private endpoints.
* The IAM role, instance profile, and security group are created.
* The volumes for the AI engine databases are created on the FSx for ONTAP system.
* The virtual machine instance for the AI engine is deployed.
