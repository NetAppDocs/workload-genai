---
sidebar: sidebar
permalink: deploy-infrastructure.html
keywords: ai, chatbot, infrastructure, bedrock, fsx for ontap
summary: You need to deploy the infrastructure for RAG framework in your environment before you can build FSx for ONTAP knowledge bases and applications for your organization. The primary infrastructure components are the Amazon Bedrock AI service, a virtual machine instance for the NetApp GenAI engine, and an FSx for ONTAP file system.
---

= Deploy the knowledge base infrastructure
:icons: font
:imagesdir: ./media/

[.lead]
You need to deploy the infrastructure for RAG framework in your environment before you can build FSx for ONTAP knowledge bases and applications for your organization. The primary infrastructure components are the Amazon Bedrock AI service, a virtual machine instance for the NetApp GenAI engine, and an FSx for ONTAP file system.

The deployed infrastructure can support multiple knowledge bases and chatbots, so you'll typically only need to perform this task once.

image:diagram-chatbot-infrastructure.png[A diagram of the AI chatbot components.]

The items in green boxes are deployed during this procedure. The other elements must be in place before starting the deployment.

== Infrastructure details

The infrastructure consists of the following components.

Amazon Bedrock service::
Amazon Bedrock is a fully managed service that enables you to use foundation models (FMs) from leading AI companies via a single API. It also provides the capabilities you need to build secure generative AI applications.
+
https://aws.amazon.com/bedrock/[Learn more about Amazon Bedrock].

Virtual machine for the NetApp GenAI engine::
The NetApp GenAI engine gets deployed during this process. It provides the processing power to ingest the data from your data sources and then write that data in the vector database.

FSx for ONTAP file system::
The FSx for ONTAP system provides the storage for your GenAI system. 
+
A single volume is deployed that will contain the vector database that stores the data that has been generated by the foundational model based on your data sources.
+
*Add details about the vector DB*
+
Your data sources that you'll integrate into your knowledge base can reside on the same FSx for ONTAP system, or on a different system.
+
The NetApp GenAI engine monitors and interacts with both of these volumes.

== Deploy the GenAI Studio RAG infrastructure

You'll need to enter your AWS credentials and select the FSx for ONTAP file system to deploy the Retrieval Augmentation Generation (RAG) infrastructure.

.Before you begin

Make sure your environment meets link:aws-requirements.html[the requirements] before you start this procedure.

.Steps

. Log in to Workload Factory.

. In the AI workloads tile, click *Deploy & manage* and the Deploy chatbot infrastructure page is displayed.

. Review the infrastructure diagram and click *Next*. 

. Complete the items in the "AWS settings" section of the Define infrastructure page: 

.. *AWS credentials*. Select or add the AWS credentials that provide permissions to deploy the AWS resources. 
//+
//When running in Basic mode you can continue without credentials, but you'll need to copy the code in the Codebox for CloudFormation and add credentials manually after you're logged into AWS.

.. *Location*. Select the AWS region, VPC, and Subnet. 
+
Your instance of Amazon Bedrock must be located in the same region and VPC.
+
Note that Amazon Bedrock is supported in the https://docs.aws.amazon.com/bedrock/latest/userguide/knowledge-base-supported.html[following regions].

. Complete the items in the "Infrastructure settings" section of the Define infrastructure page: 

.. *FSx for ONTAP system*. Select the FSx for ONTAP file system and the storage VM where the GenAI instance database volumes will be deployed, and then specify the name you want to use for the volume.
+
Depending on whether or not Workload Factory has the credentials for the FSx for ONTAP system, you may need to enter the user name and password.

.. *Tags*. Enter any tag key/value pairs that you want to have applied to all the AWS resources that are part of this deployment.

. *Key pair*. Select a key pair that allows you to securely connect to the NetApp GenAI engine instance.

. Click *Deploy* to begin the deployment.

.Result

The chatbot infrastructure is deployed and you can start to build your first knowledge base. This process can take up to 10 minutes.

During the deployment process, the following items are set up:

* The network is set up along with the private endpoints.
* The IAM role, instance profile, and security group are created.
* The volume for the GenAI engine database (LanceDB) is created on the FSx for ONTAP system.
* The virtual machine instance for the GenAI engine is deployed.
