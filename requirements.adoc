---
sidebar: sidebar
permalink: requirements.html
keywords: ai, chatbot, prerequisites, bedrock, fsx for ontap, prerequisites, requirements
summary: Ensure that workload factory and AWS are set up properly before you build your knowledge base. This includes having your AWS log in credentials, a deployed FSx for ONTAP file system that contains the data sources you want to integrate in your knowledge base, access to the Amazon Bedrock AI service, and more.
---

= GenAI requirements
:icons: font
:imagesdir: ./media/

[.lead]
Ensure that workload factory and AWS are set up properly before you build your knowledge base. This includes having your AWS log in credentials, a deployed FSx for ONTAP file system that contains the data sources you want to integrate in your knowledge base, access to the Amazon Bedrock AI service, and more.

== Basic GenAI requirements
GenAI has general requirements that your environment needs to meet before you get started.

Workload factory login and account::
You'll need to https://docs.netapp.com/us-en/workload-setup-admin/sign-up-saas.html[set up an account with workload factory^] and log in using one of the https://docs.netapp.com/us-en/workload-setup-admin/console-experiences.html[console experiences^].

AWS credentials and permissions::
You need to add AWS credentials to workload factory with read/write permissions, which means you'll be using workload factory in _Read/Write_ mode for GenAI.
+
_Basic_ mode and _Read-only_ mode permissions are not supported at this time.
+
When setting up your credentials, selecting permissions as shown below provides you with full access to manage FSx for ONTAP file systems and to deploy and manage the GenAI EC2 instance and other AWS resources needed for your knowledge base and chatbot.
+
image:screenshot-ai-permissions.png[A screenshot showing the permissions setting for full management of AI resources.]
+
https://docs.netapp.com/us-en/workload-setup-admin/add-credentials.html[Learn how to add AWS credentials to workload factory^]

== GenAI knowledge base requirements
If you plan to work with knowledge bases, ensure your environment meets the following requirements.

Amazon Bedrock::
Amazon Bedrock enables you to use foundation models and it provides the capabilities to build generative AI applications.
+
Before you get started with BlueXP workload factory for GenAI, you must set up Amazon Bedrock. Your GenAI deployment must be in an AWS region that has Amazon Bedrock enabled.
+
* https://docs.aws.amazon.com/bedrock/latest/userguide/setting-up.html[AWS documentation: Set up Amazon Bedrock^]
* https://docs.aws.amazon.com/bedrock/latest/userguide/knowledge-base-supported.html[AWS documentation: Supported regions and models for Knowledge bases for Amazon Bedrock^]

+
GenAI re-ranks search results by default to improve result relevancy. For the best results, ensure that your Amazon Bedrock foundation model configuration includes access to a re-rank model, such as Cohere Rerank or Amazon Rerank, if available in your region.

Embedding model::
You must enable the embedding model that you plan to use before creating your knowledge base. The following embedding models are supported:
+
* Titan Embeddings G1 - Text
* Titan Embedding Text v2
* Titan Multimodal Embeddings G1
* Embed English
* Embed Multilingual
+
https://aws.amazon.com/bedrock/titan/[Learn more about Amazon Titan^]

Chat model::
You must enable the foundational chat model that you plan to use before creating your knowledge base. Since model support varies by AWS region, refer to https://docs.aws.amazon.com/bedrock/latest/userguide/models-regions.html[the AWS documentation^] to verify which models you can use in the regions where you plan to deploy your knowledge base. 
+
GenAI supports various models from Anthropic, Amazon, Mistral AI, Meta, Jamba, and Cohere.
+
Learn more about using these models in Amazon Bedrock:
+
* https://aws.amazon.com/bedrock/claude/[Anthropic's Claude in Amazon Bedrock^]
* https://docs.aws.amazon.com/nova/latest/userguide/getting-started-console.html[Getting started with Amazon Nova in the Amazon Bedrock console^]
* https://aws.amazon.com/bedrock/mistral/[Mistral AI models^]
* https://docs.aws.amazon.com/bedrock/latest/userguide/titan-text-models.html[Amazon Titan text models^]
* https://aws.amazon.com/bedrock/llama/[Meta Llama models^]
* https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-jamba.html[Jamba models^]
* https://aws.amazon.com/bedrock/cohere/[Cohere Command models^]

FSx for ONTAP file system::
You need a minimum of one FSx for ONTAP file system:
+
* One file system will be used (or created, if it doesn't exist) by the NetApp GenAI engine to store the vector database used by the knowledge base. 
+
This FSx for ONTAP file system must use FlexVol volumes. FlexGroup volumes are not supported.

* One or more file systems will contain the data sources that you'll be integrating into your knowledge base. 
+
One FSx for ONTAP file system can be used for both of these purposes, or you can use multiple FSx for ONTAP file systems.

* You'll need to know the AWS region, VPC, and subnet where the AWS FSx for ONTAP file system resides. The file system must be in an AWS region that has Amazon Bedrock enabled.

* You'll need to consider the tag key/value pairs that you want to apply to the AWS resources that are part of this deployment (optional).

* You'll need to know the key pair information that allows you to securely connect to the NetApp AI engine instance.

+
https://docs.netapp.com/us-en/workload-fsx-ontap/create-file-system.html[Learn how to deploy and manage FSx for ONTAP file systems^]

== Requirements for Amazon Q Business integration
If you plan to integrate GenAI with Amazon Q Business, ensure your environment meets the following requirements.

Amazon Q Business::

* Ensure that you have created an Amazon Q Business application.
* Ensure that your Amazon Q application exists in one of your AWS regions.
* Ensure that you have https://docs.aws.amazon.com/amazonq/latest/qbusiness-ug/select-retriever.html[created an index^] for your Amazon Q Business application. 
* Ensure that your Amazon Q Business application is not in a failed state.

FSx for ONTAP file system::
You need a minimum of one FSx for ONTAP file system:
+
* One file system will be used (or created, if it doesn't exist) by the NetApp GenAI engine to store information about the connector. 
+
This FSx for ONTAP file system must use FlexVol volumes. FlexGroup volumes are not supported.

* One or more file systems will contain the data sources that you'll be adding to your connector. 
+
One FSx for ONTAP file system can be used for both of these purposes, or you can use multiple FSx for ONTAP file systems.

* You'll need to know the AWS region, VPC, and subnet where the AWS FSx for ONTAP file system resides.

* You'll need to consider the tag key/value pairs that you want to apply to the AWS resources that are part of this deployment (optional).

* You'll need to know the key pair information that allows you to securely connect to the NetApp AI engine instance.

+
https://docs.netapp.com/us-en/workload-fsx-ontap/create-file-system.html[Learn how to deploy and manage FSx for ONTAP file systems^]